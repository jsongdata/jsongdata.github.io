{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIM3EtYg0ltJ"
      },
      "source": [
        "#Introduction to Python Asyncronous ProgrammingI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ca7vHtJ2O6E"
      },
      "source": [
        "###The Paradigm Shift in Concurrent Programming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH-ynckM2Kew"
      },
      "source": [
        "The Paradigm Shift in Concurrent Programming\n",
        "Traditionally, concurrent programming has been achieved by utilizing multiple threads. However, as those who have experience with manual threading can attest, writing thread-safe code is incredibly challenging. Furthermore, running multi-threaded programs on single-core processors often results in negligible performance gains—or even degradation—due to the overhead of context switching.\n",
        "\n",
        "This is why asynchronous programming, which handles concurrency within a single thread, has recently gained significant traction. It has become essential for modern, large-scale applications to efficiently manage tasks such as parallel processing, network communication, and database integration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuSamJBC2Xmn"
      },
      "source": [
        "###Non-blocking I/O and the Evolution of Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf0BouUL2aNv"
      },
      "source": [
        "When developing applications like web servers, you will find that the time spent waiting for database or API responses far exceeds the time spent on actual CPU computation. Asynchronous programming prevents the CPU from idling during these I/O-bound wait times, allowing it to handle other tasks instead. This concept is commonly referred to as non-blocking.\n",
        "\n",
        "While this model is native to languages like JavaScript, it was once a foreign concept to Python, which is fundamentally synchronous by design. However, with the introduction of the asyncio module in Python 3.4 and the official adoption of the async/await syntax in Python 3.5, asynchronous programming is now a built-in standard in the Python ecosystem, requiring no external libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXakEJyAt10n"
      },
      "source": [
        "###Simple test before we begin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc11DK3A1Oqw"
      },
      "source": [
        "Before we begin, we will explore the functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DkbLQtgphW-v"
      },
      "outputs": [],
      "source": [
        "def do_sync():\n",
        "  return 'sync'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iHn61h4yh5Pk",
        "outputId": "a31a7800-5456-4e2a-e843-eac4ffb0a04d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sync'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "do_sync()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QANKP2ayiBdA"
      },
      "outputs": [],
      "source": [
        "async def do_async():\n",
        "  return 'async'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inzZtknOiSrG",
        "outputId": "737261b7-3bc7-44b2-aea9-3df9875bccaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<coroutine object do_async at 0x790685db2fb0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "do_async()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnq2oAkEib8m"
      },
      "source": [
        "From the test above, we learned the fact that async fn cannot be called like how sync fn is called. We need to use **await** keyword."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0qJ6Svk8jlti",
        "outputId": "c0ef6d1e-6cb9-4202-d323-cda19bd16c6b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'async'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await do_async()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-lba6ikkuPC"
      },
      "source": [
        "Now, 'async' is printed correctly. This behavior is consistent with JavaScript, which returns a 'promise' object unless the await keyword is specified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0lhsT-Ft-Rx"
      },
      "source": [
        "###Syncronous funciton example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yual2fIXlHJS"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def find_users_sync(n):\n",
        "  for i in range(1, n+1):\n",
        "    print(f'{i}th user is being searched out of {n} people...')\n",
        "    time.sleep(1) # intentional 1 second delay\n",
        "  print(f'Total {n} people have been searched!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "19UxJNo6nk2i"
      },
      "outputs": [],
      "source": [
        "def process_sync():\n",
        "  start = time.time()\n",
        "  find_users_sync(3)\n",
        "  find_users_sync(2)\n",
        "  find_users_sync(1)\n",
        "  end = time.time()\n",
        "  print(f' >>> total time taken for sync process: {end-start}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yojDrAK3otzb",
        "outputId": "3f972dcb-f551-44ac-bdbb-071baf4f87e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1th user is being searched out of 3 people...\n",
            "2th user is being searched out of 3 people...\n",
            "3th user is being searched out of 3 people...\n",
            "Total 3 people have been searched!\n",
            "1th user is being searched out of 2 people...\n",
            "2th user is being searched out of 2 people...\n",
            "Total 2 people have been searched!\n",
            "1th user is being searched out of 1 people...\n",
            "Total 1 people have been searched!\n",
            " >>> total time taken for sync process: 6.00173020362854\n"
          ]
        }
      ],
      "source": [
        "process_sync()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwEnNoZxovVF"
      },
      "source": [
        "Above is to show how a single thread web-server would work. 2nd function could start running when the 1st function finishes running by 100%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFEclJWWtpqq"
      },
      "source": [
        "###Asyncronous Function example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wsE-HUiOpYar"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "async def find_users_async(n):\n",
        "  for i in range(1, n+1):\n",
        "    print(f'{i}th user is being searched out of {n} people...')\n",
        "    await asyncio.sleep(1)\n",
        "  print(f'Total {n} people have been searched!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iTL48V-Su0qd"
      },
      "outputs": [],
      "source": [
        "async def process_async():\n",
        "  start = time.time()\n",
        "  await asyncio.gather(  # --> By gather(), Python's event loop allowes to schedule and call three functions automatically and syncronously.\n",
        "      find_users_async(3),\n",
        "      find_users_async(2),\n",
        "      find_users_async(1),\n",
        "  )\n",
        "  end = time.time()\n",
        "  print(f' >>> total time taken for sync process: {end-start}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbmbdqPJxBV0",
        "outputId": "a41716bb-8a91-463b-d9ce-b9ec54cb490e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<coroutine object process_async at 0x790684cea980>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "process_async()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwoFTY0XxGHO"
      },
      "source": [
        "Again, do not call this without 'await' keyword. You get 'coroutine' object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-FQnIUMxHaY",
        "outputId": "ed17f095-80f5-427e-d9d2-557d2458907f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1th user is being searched out of 3 people...\n",
            "1th user is being searched out of 2 people...\n",
            "1th user is being searched out of 1 people...\n",
            "2th user is being searched out of 3 people...\n",
            "2th user is being searched out of 2 people...\n",
            "Total 1 people have been searched!\n",
            "3th user is being searched out of 3 people...\n",
            "Total 2 people have been searched!\n",
            "Total 3 people have been searched!\n",
            " >>> total time taken for sync process: 3.004930019378662\n"
          ]
        }
      ],
      "source": [
        "await process_async()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3PKoAAcxpuG"
      },
      "source": [
        "Now, 6sec became 3sec. We saved the running time by 2x by running the same code asychronously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsYs2rIHxRjQ"
      },
      "source": [
        "###How this can help LLMOps engineer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-qwBNIB2ljv"
      },
      "source": [
        "Since LLM API calls and database lookups are typical I/O-bound tasks with long wait times, Asyncio provides a non-blocking structure that prevents resource waste by allowing the CPU to handle other tasks while waiting for network responses. This enables parallel processing of multiple API calls in RAG pipelines or multi-agent environments, drastically reducing system latency, and is essential for building high-performance serving layers based on FastAPI by efficiently managing large-scale concurrent connections even on a single thread. Ultimately, the ability to ensure high throughput and reduce operational costs with limited resources becomes a core competitive advantage for LLMOps engineers."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
